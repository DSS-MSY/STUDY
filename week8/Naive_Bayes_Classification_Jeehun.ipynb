{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classification(나이브 베이즈 분류)\n",
    "2017.11.27<br>\n",
    "박지훈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__베이즈 정리(Bayes's Theorem)__: 불확실성 하에서 의사결정문제를 수학적으로 다둘 때 중요하게 사용된다. 전통적인 확률이 연역적 추론에 기반을 두고 있다면 베이즈 정리는 확률임에도 불구하고 귀납적, 경험적인 추론을 사용한다. <br>\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$ <br>\n",
    "\n",
    "__조건부 확률(Conditional Probability)__: 어떤 특정 사건 B가 발생했을때 사건 A가 발생할 확률 수식으로는 $P(A|B)$ 로 표현한다.<br>\n",
    "각 사건이 독립일 경우 조건부 확률은 각 사건의 곱과 같다. 그러므로 $P(A|B) = P(A)$이고 $P(B|A) = P(B)$ 이다. <br>\n",
    "\n",
    "__라플라스 스무딩(Laplace Smoothing)__: 그 전에 관측되지 못한 새로운 데이터를 분류해야 할때 확률값이 0이되는걸 막기위해 분자와 분모에 1씩 더한다. <br>\n",
    "\n",
    "__언더플로우(underflow)__: 확률을 구하다보면 0에 가까운 숫자들을 곱하게된다. 그 결과 메모리가 표현할 수 있는 수보다 작은수가 생겨 0으로 표현되게된다. 이를 언더플로우라고 하는데 이를 방지하기위해 log를 사용한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a dataset\n",
    "def make_data():\n",
    "    data = np.array([[1, 1, 1, 0],\n",
    "                     [1, 1, 1, 1], \n",
    "                     [1, 0, 0, 1], \n",
    "                     [0, 1, 1, 1], \n",
    "                     [1, 1, 1, 0], \n",
    "                     [0, 0, 1, 0], \n",
    "                     [0, 1, 0, 1], \n",
    "                     [1, 0, 1, 0], \n",
    "                     [1, 0, 0, 0], \n",
    "                     [0, 0, 1, 1]])\n",
    "    \n",
    "    classes = np.array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0])\n",
    "    \n",
    "    return data, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_prob(dataset, classes):\n",
    "    \n",
    "    class_unique = np.unique(classes)\n",
    "    class_prob = []\n",
    "    data_split = []\n",
    "    con_prob = []\n",
    "    con_prob_2 = []\n",
    "    temp_1 = []\n",
    "    temp_2 = []\n",
    "    prob = []\n",
    "    \n",
    "    for i in class_unique:\n",
    "        class_prob.append(len(classes[classes==i])/len(classes))\n",
    "        data_split.append(dataset[classes==i])\n",
    "    \n",
    "    for j in range(len(data_split)):\n",
    "#        con_prob.append(np.sum(data_split[j], axis=0))\n",
    "        \n",
    "        for k in class_unique:\n",
    "            \n",
    "            for l in range(len(dataset[0])):\n",
    "                temp_1.append(len(data_split[j][data_split[j][:, l]==k])/len(data_split[j]))\n",
    "\n",
    "            temp_2.append(temp_1)\n",
    "            temp_1 = []\n",
    "\n",
    "        con_prob_2.append(temp_2)\n",
    "        temp_2 = []\n",
    "    \n",
    "#    for n in range(len(data_split)):\n",
    "#        prob.append(con_prob[n]/len(data_split[n]))\n",
    "\n",
    "    return class_unique, class_prob, data_split, con_prob_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def classification(dataset, classes, classification_data):\n",
    "    class_unique, class_prob, data_split, con_prob_2 = count_prob(dataset, classes)\n",
    "    log_prob = np.log2(con_prob_2)\n",
    "    temp = []\n",
    "    prob = {}\n",
    "    \n",
    "    for i in range(len(con_prob_2)):\n",
    "        for j in range(len(classification_data)):\n",
    "            temp.append(log_prob[i][classification_data[j]][j])\n",
    "            \n",
    "        prob.update({i:np.sum(temp)})\n",
    "        temp = []\n",
    "\n",
    "    #print(con_prob_2[0][dataset[0]==np.unique(classes)])\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset, classes = make_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_unique, class_prob, data_split, con_prob_2 = count_prob(dataset, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -4.7548875021634682, 1: -1.6601499971153753}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification(dataset, classes, [1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
