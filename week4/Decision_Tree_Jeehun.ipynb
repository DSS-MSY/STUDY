{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree(의사결정나무)\n",
    "2017.11.04<br>\n",
    "박지훈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "의사결정나무는 데이터를 분류(Classification)하기 위해 사용된다.<br> \n",
    "엔트로피: 데이터 집합의 혼잡도. 주어진 집합에 서로다른 라벨이 있으면 엔트로피가 올라간다. 의사결정나무에서는 엔트로피를 낮은상태로 변환시키는데 이 과정에서 분류가 이루어진다.. 의사결정나무의 평가지수로 쓰인다.<br>\n",
    "정보획득량(Information gain): 상위노드와 하위노드 사이의 엔트로피 차이. 노드가 생기면서 분류를 하는데, 그 결과 얼마나 많은 정보를 획득했는지 알려준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "version_01<br>\n",
    "numpy, 엔트로피"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing package\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sample\n",
    "def make_sample():\n",
    "    dataset = np.array([[0, 1, 1, 'yes'],\n",
    "                        [0, 1, 0, 'no'],\n",
    "                        [1, 0, 1, 'no'],\n",
    "                        [1, 1, 1, 'no'],\n",
    "                        [0, 1, 0, 'no'],\n",
    "                        [0, 0, 1, 'no'],\n",
    "                        [1, 0, 1, 'no'],\n",
    "                        [1, 1, 0, 'no']])\n",
    "    \n",
    "    y = dataset[:, -1]\n",
    "\n",
    "    labels = ['cartoon', 'winter', 'more than 1 person']\n",
    "    \n",
    "    return dataset, y, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ent(dataset):\n",
    "    ent = []\n",
    "    temp_ent = 0.0\n",
    "    prob = 0.0\n",
    "    for i in np.arange(0, len(dataset[0])-1):\n",
    "        label = np.unique(dataset[:, i])\n",
    "        for j in label:\n",
    "            node = dataset[:, i]==j\n",
    "            node = dataset[:, -1][node]\n",
    "            node_label = pd.unique(node)\n",
    "            for k in node_label:\n",
    "                prob = len(node[node==k])/len(node)\n",
    "                temp_ent -= prob * np.log2(prob) * len(node)/len(dataset.iloc[:, i])\n",
    "        ent.append(temp_ent)\n",
    "        temp_ent = 0.0\n",
    "       \n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset, feat):\n",
    "    new_data = []\n",
    "    col = np.arange(len(dataset[0]))\n",
    "    trim_data = dataset[:, col!=feat]\n",
    "    for i in np.unique(dataset[:, feat]):\n",
    "        new_data.append(trim_data[dataset[:, feat]==i])\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_feat(ent):\n",
    "    feat = ent.index(sorted(ent)[0])\n",
    "    \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulid_tree(dataset):\n",
    "    feat_list = []\n",
    "    ent = cal_ent(dataset)\n",
    "    feat = ent.index(sorted(ent)[0])\n",
    "    feat_list.append(feat)\n",
    "    \n",
    "    dataset = split_data(dataset, feat)\n",
    "    \n",
    "    return dataset, feat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulid_tree(dataset, labels):\n",
    "    feat_list = []\n",
    "    label_list = []\n",
    "\n",
    "    ent = cal_ent(dataset)\n",
    "    feat = ent.index(sorted(ent)[0])\n",
    "    feat_list.append(feat)\n",
    "\n",
    "    new_data = split_data(dataset, feat)\n",
    "    \n",
    "    for i in np.arange(len(new_data)):\n",
    "        ent = cal_ent(new_data[i])\n",
    "        feat = ent.index(sorted(ent)[0])\n",
    "        feat_list.append(feat)\n",
    "        label_list.append(labels.pop(feat))\n",
    "        \n",
    "    return feat_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulid_tree(dataset, labels):\n",
    "    feat_list = []\n",
    "    label_list = []\n",
    "    new_data = []\n",
    "    \n",
    "    ent = cal_ent(dataset)\n",
    "    feat = ent.index(sorted(ent)[0])\n",
    "    feat_list.append(feat)\n",
    "\n",
    "    new_data = split_data(dataset, feat)\n",
    "    \n",
    "    for i in np.arange(len(new_data)):\n",
    "        ent = cal_ent(new_data[i])\n",
    "        feat = ent.index(sorted(ent)[0])\n",
    "        temp_data = split_data(new_data[i], feat)\n",
    "        feat_list.append(feat)\n",
    "        label_list.append(labels.pop(feat))\n",
    "        \n",
    "    return feat_list, label_list, new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulid_tree(dataset, labels):\n",
    "    feat_list = []\n",
    "    label_list = []\n",
    "    new_data = []\n",
    "    \n",
    "    for i in np.arange(len(dataset[0])-1):    \n",
    "        ent = cal_ent(dataset)\n",
    "        feat = ent.index(sorted(ent)[0])\n",
    "        feat_list.append(feat)\n",
    "\n",
    "    new_data = split_data(dataset, feat)\n",
    "    \n",
    "    for i in np.arange(len(new_data)):\n",
    "        ent = cal_ent(new_data[i])\n",
    "        feat = ent.index(sorted(ent)[0])\n",
    "        temp_data = split_data(new_data[i], feat)\n",
    "        feat_list.append(feat)\n",
    "        label_list.append(labels.pop(feat))\n",
    "        \n",
    "    return feat_list, label_list, new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, y, labels = make_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.81127812445913283, 0.72192809488736231, 0.72192809488736231]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_ent(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1, 0, 0], ['cartoon', 'winter'], [array([['1', '1', 'no'],\n",
       "         ['0', '1', 'no'],\n",
       "         ['1', '1', 'no']],\n",
       "        dtype='<U11'), array([['0', '1', 'yes'],\n",
       "         ['0', '0', 'no'],\n",
       "         ['1', '1', 'no'],\n",
       "         ['0', '0', 'no'],\n",
       "         ['1', '0', 'no']],\n",
       "        dtype='<U11')])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bulid_tree(dataset, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "version_02<br>\n",
    "pandas, 엔트로피"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sample\n",
    "def make_sample():\n",
    "    dataset = pd.DataFrame([[0, 1, 1, 'yes'],\n",
    "                            [0, 1, 0, 'no'],\n",
    "                            [1, 0, 1, 'no'],\n",
    "                            [1, 1, 1, 'no'],\n",
    "                            [0, 1, 0, 'no'],\n",
    "                            [0, 0, 1, 'no'],\n",
    "                            [1, 0, 1, 'no'],\n",
    "                            [1, 1, 0, 'no']], columns = ['cartoon', 'winter', 'more than 1 person', 'label'])\n",
    "    \n",
    "    y = dataset.iloc[:, -1]\n",
    "\n",
    "    labels = ['cartoon', 'winter', 'more than 1 person']\n",
    "    \n",
    "    return dataset, y, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating entropy\n",
    "def cal_ent(dataset):\n",
    "    ent = []\n",
    "    col_ent = 0.0\n",
    "    prob = 0.0\n",
    "    for i in np.arange(len(dataset.columns)-1):\n",
    "        label = np.unique(dataset.iloc[:, i])\n",
    "        for j in label:\n",
    "            node = dataset.iloc[:, i]==j\n",
    "            node = dataset.iloc[:, -1][node]\n",
    "            node_label = pd.unique(node)\n",
    "            for k in node_label:\n",
    "                prob = len(node[node==k])/len(node)\n",
    "                col_ent -= prob * np.log2(prob) * len(node)/len(dataset.iloc[:, i])\n",
    "\n",
    "        ent.append(col_ent)\n",
    "        col_ent = 0.0\n",
    "       \n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting dataset\n",
    "def split_data(dataset, feat):\n",
    "    new_data = []\n",
    "    col = np.arange(len(dataset.columns))\n",
    "    trim_data = dataset.iloc[:, col!=feat]\n",
    "    for i in np.unique(dataset.iloc[:, feat]):\n",
    "        #new_data.append(pd.DataFrame(trim_data[dataset.iloc[:, feat]==i]))\n",
    "        new_data.append(trim_data[dataset.iloc[:, feat]==i])\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# planting tree\n",
    "def bulid_tree(dataset, depth):\n",
    "    temp_data = []\n",
    "    select_feat = []\n",
    "    ent = cal_ent(dataset)\n",
    "    feat = ent.index(sorted(ent)[0])\n",
    "    select_feat.append(dataset.columns[feat])\n",
    "    dataset = split_data(dataset, feat)\n",
    "    \n",
    "    for i in np.arange(depth):\n",
    "        for j in np.arange(len(dataset)):\n",
    "            ent = cal_ent(dataset[j])\n",
    "            feat = ent.index(sorted(ent)[0])\n",
    "            temp_data.extend(split_data(dataset[j], feat))\n",
    "    \n",
    "    if temp_data:\n",
    "        dataset.append(temp_data)\n",
    "\n",
    "    return dataset, select_feat, feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, y, labels = make_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b= bulid_tree(dataset, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40563906222956642, 0.45120505930460142, 0.45120505930460142]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_ent(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
